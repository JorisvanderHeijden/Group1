{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN Addition Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "from six.moves import range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CharacterTable(object):\n",
    "    \"\"\"Given a set of characters:\n",
    "    + Encode them to a one hot integer representation\n",
    "    + Decode the one hot integer representation to their character output\n",
    "    + Decode a vector of probabilities to their character output\n",
    "    \"\"\"\n",
    "    def __init__(self, chars):\n",
    "        \"\"\"Initialize character table.\n",
    "        # Arguments\n",
    "            chars: Characters that can appear in the input.\n",
    "        \"\"\"\n",
    "        self.chars = sorted(set(chars))\n",
    "        self.char_indices = dict((c, i) for i, c in enumerate(self.chars))\n",
    "        self.indices_char = dict((i, c) for i, c in enumerate(self.chars))\n",
    "\n",
    "    def encode(self, C, num_rows):\n",
    "        \"\"\"One hot encode given string C.\n",
    "        # Arguments\n",
    "            num_rows: Number of rows in the returned one hot encoding. This is\n",
    "                used to keep the # of rows for each data the same.\n",
    "        \"\"\"\n",
    "        x = np.zeros((num_rows, len(self.chars)))\n",
    "        for i, c in enumerate(C):\n",
    "            x[i, self.char_indices[c]] = 1\n",
    "        return x\n",
    "\n",
    "    def decode(self, x, calc_argmax=True):\n",
    "        if calc_argmax:\n",
    "            x = x.argmax(axis=-1)\n",
    "        return ''.join(self.indices_char[x] for x in x)\n",
    "\n",
    "\n",
    "class colors:\n",
    "    ok = '\\033[92m'\n",
    "    fail = '\\033[91m'\n",
    "    close = '\\033[0m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total addition questions: 50000\n",
      "[[ True False False False False False False False False False False False]\n",
      " [ True False False False False False False False False False False False]\n",
      " [ True False False False False False False False False False False False]\n",
      " [False False False False False False False False False False False  True]\n",
      " [False  True False False False False False False False False False False]\n",
      " [False False False False False  True False False False False False False]\n",
      " [False False False False False False False False False  True False False]]\n",
      "   9+37\n",
      "[[False False False False False False False False False False  True False]\n",
      " [False False False False  True False False False False False False False]\n",
      " [ True False False False False False False False False False False False]\n",
      " [ True False False False False False False False False False False False]]\n",
      "82  \n",
      "Training Data:\n",
      "(45000, 7, 12)\n",
      "(45000, 4, 12)\n",
      "Validation Data:\n",
      "(5000, 7, 12)\n",
      "(5000, 4, 12)\n"
     ]
    }
   ],
   "source": [
    "# Parameters for the model and dataset.\n",
    "TRAINING_SIZE = 50000\n",
    "DIGITS = 3\n",
    "REVERSE = True\n",
    "\n",
    "# Maximum length of input is 'int + int' (e.g., '345+678'). Maximum length of\n",
    "# int is DIGITS.\n",
    "MAXLEN = DIGITS + 1 + DIGITS\n",
    "\n",
    "# All the numbers, plus sign and space for padding.\n",
    "chars = '0123456789+ '\n",
    "ctable = CharacterTable(chars)\n",
    "\n",
    "# Generate training and test data\n",
    "questions = []\n",
    "expected = []\n",
    "seen = set()\n",
    "while len(questions) < TRAINING_SIZE:\n",
    "    f = lambda: int(''.join(np.random.choice(list('0123456789'))\n",
    "                    for i in range(np.random.randint(1, DIGITS + 1))))\n",
    "    a, b = f(), f()\n",
    "    # Skip any addition questions we've already seen\n",
    "    # Also skip any such that x+Y == Y+x (hence the sorting).\n",
    "    key = tuple(sorted((a, b)))\n",
    "    if key in seen:\n",
    "        continue\n",
    "    seen.add(key)\n",
    "    # Pad the data with spaces such that it is always MAXLEN.\n",
    "    q = '{}+{}'.format(a, b)\n",
    "    query = q + ' ' * (MAXLEN - len(q))\n",
    "    ans = str(a + b)\n",
    "    # Answers can be of maximum size DIGITS + 1.\n",
    "    ans += ' ' * (DIGITS + 1 - len(ans))\n",
    "    if REVERSE:\n",
    "        # Reverse the query, e.g., '12+345  ' becomes '  543+21'. (Note the\n",
    "        # space used for padding.)\n",
    "        query = query[::-1]\n",
    "    questions.append(query)\n",
    "    expected.append(ans)\n",
    "print('Total addition questions:', len(questions))\n",
    "\n",
    "# Vectorize training and test data\n",
    "x = np.zeros((len(questions), MAXLEN, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(questions), DIGITS + 1, len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(questions):\n",
    "    x[i] = ctable.encode(sentence, MAXLEN)\n",
    "for i, sentence in enumerate(expected):\n",
    "    y[i] = ctable.encode(sentence, DIGITS + 1)\n",
    "\n",
    "print(x[0])\n",
    "print(questions[0]) # order: \" +0123456789\"\n",
    "\n",
    "print(y[0])\n",
    "print(expected[0])\n",
    "\n",
    "# Shuffle (x, y) in unison as the later parts of x will almost all be larger\n",
    "# digits.\n",
    "indices = np.arange(len(y))\n",
    "np.random.shuffle(indices)\n",
    "x = x[indices]\n",
    "y = y[indices]\n",
    "\n",
    "# Explicitly set apart 10% for validation data that we never train over.\n",
    "split_at = len(x) - len(x) // 10\n",
    "(x_train, x_val) = x[:split_at], x[split_at:]\n",
    "(y_train, y_val) = y[:split_at], y[split_at:]\n",
    "\n",
    "print('Training Data:')\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print('Validation Data:')\n",
    "print(x_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ True False False False False False False False False False False False]\n",
      " [False False False  True False False False False False False False False]\n",
      " [False False False False False False  True False False False False False]\n",
      " [False  True False False False False False False False False False False]\n",
      " [False False False False False False False False False False False  True]\n",
      " [False False  True False False False False False False False False False]\n",
      " [False False False False False False  True False False False False False]]\n",
      "  58+68\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 128)               72192     \n",
      "_________________________________________________________________\n",
      "repeat_vector_1 (RepeatVecto (None, 4, 128)            0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 4, 128)            131584    \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 4, 12)             1548      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 4, 12)             0         \n",
      "=================================================================\n",
      "Total params: 205,324\n",
      "Trainable params: 205,324\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Try replacing GRU, or SimpleRNN.\n",
    "RNN = layers.LSTM\n",
    "HIDDEN_SIZE = 128\n",
    "BATCH_SIZE = 128\n",
    "LAYERS = 1\n",
    "\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "# \"Encode\" the input sequence using an RNN, producing an output of HIDDEN_SIZE.\n",
    "model.add(RNN(HIDDEN_SIZE, input_shape=(MAXLEN, len(chars))))\n",
    "# As the decoder RNN's input, repeatedly provide with the last hidden state of\n",
    "# RNN for each time step. Repeat 'DIGITS + 1' times as that's the maximum\n",
    "# length of output, e.g., when DIGITS=3, max output is 999+999=1998.\n",
    "model.add(layers.RepeatVector(DIGITS + 1))\n",
    "# The decoder RNN could be multiple layers stacked or a single layer.\n",
    "for _ in range(LAYERS):\n",
    "    # By setting return_sequences to True, return not only the last output but\n",
    "    # all the outputs so far. \n",
    "    # This is necessary as TimeDistributed in the below expects\n",
    "    # the first dimension to be the timesteps.\n",
    "    model.add(RNN(HIDDEN_SIZE, return_sequences=True))\n",
    "\n",
    "# Apply a dense layer to the every temporal slice of an input. For each of step\n",
    "# of the output sequence, decide which character should be chosen.\n",
    "model.add(layers.TimeDistributed(layers.Dense(len(chars))))\n",
    "model.add(layers.Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 10s 228us/step - loss: 0.1143 - acc: 0.9794 - val_loss: 0.1000 - val_acc: 0.9830\n",
      "Question   Prediction   Answer\n",
      "620+912    1532         1532    \u001b[92m ☑ \u001b[0m\n",
      "64+231     295          295     \u001b[92m ☑ \u001b[0m\n",
      "581+100    681          681     \u001b[92m ☑ \u001b[0m\n",
      "747+15     762          762     \u001b[92m ☑ \u001b[0m\n",
      "45+82      127          127     \u001b[92m ☑ \u001b[0m\n",
      "320+72     392          392     \u001b[92m ☑ \u001b[0m\n",
      "61+60      121          121     \u001b[92m ☑ \u001b[0m\n",
      "38+34      72           72      \u001b[92m ☑ \u001b[0m\n",
      "160+100    270          260     \u001b[91m ☒ \u001b[0m\n",
      "36+184     220          220     \u001b[92m ☑ \u001b[0m\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 10s 228us/step - loss: 0.0869 - acc: 0.9864 - val_loss: 0.0932 - val_acc: 0.9815\n",
      "Question   Prediction   Answer\n",
      "334+4      338          338     \u001b[92m ☑ \u001b[0m\n",
      "110+421    531          531     \u001b[92m ☑ \u001b[0m\n",
      "46+14      50           60      \u001b[91m ☒ \u001b[0m\n",
      "302+39     341          341     \u001b[92m ☑ \u001b[0m\n",
      "693+0      693          693     \u001b[92m ☑ \u001b[0m\n",
      "60+12      72           72      \u001b[92m ☑ \u001b[0m\n",
      "95+658     753          753     \u001b[92m ☑ \u001b[0m\n",
      "23+506     529          529     \u001b[92m ☑ \u001b[0m\n",
      "184+3      187          187     \u001b[92m ☑ \u001b[0m\n",
      "315+286    601          601     \u001b[92m ☑ \u001b[0m\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 3\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 10s 231us/step - loss: 0.0733 - acc: 0.9884 - val_loss: 0.1049 - val_acc: 0.9716\n",
      "Question   Prediction   Answer\n",
      "0+572      572          572     \u001b[92m ☑ \u001b[0m\n",
      "49+786     835          835     \u001b[92m ☑ \u001b[0m\n",
      "461+1      462          462     \u001b[92m ☑ \u001b[0m\n",
      "173+64     237          237     \u001b[92m ☑ \u001b[0m\n",
      "19+833     852          852     \u001b[92m ☑ \u001b[0m\n",
      "85+985     1070         1070    \u001b[92m ☑ \u001b[0m\n",
      "99+971     1060         1070    \u001b[91m ☒ \u001b[0m\n",
      "54+624     678          678     \u001b[92m ☑ \u001b[0m\n",
      "186+20     206          206     \u001b[92m ☑ \u001b[0m\n",
      "717+445    1162         1162    \u001b[92m ☑ \u001b[0m\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 4\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 10s 232us/step - loss: 0.0674 - acc: 0.9878 - val_loss: 0.0497 - val_acc: 0.9946\n",
      "Question   Prediction   Answer\n",
      "8+993      1001         1001    \u001b[92m ☑ \u001b[0m\n",
      "15+156     171          171     \u001b[92m ☑ \u001b[0m\n",
      "793+276    1069         1069    \u001b[92m ☑ \u001b[0m\n",
      "808+717    1525         1525    \u001b[92m ☑ \u001b[0m\n",
      "15+50      65           65      \u001b[92m ☑ \u001b[0m\n",
      "47+509     556          556     \u001b[92m ☑ \u001b[0m\n",
      "84+638     722          722     \u001b[92m ☑ \u001b[0m\n",
      "604+714    1318         1318    \u001b[92m ☑ \u001b[0m\n",
      "83+346     429          429     \u001b[92m ☑ \u001b[0m\n",
      "375+54     429          429     \u001b[92m ☑ \u001b[0m\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 5\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 11s 236us/step - loss: 0.0453 - acc: 0.9945 - val_loss: 0.0784 - val_acc: 0.9776\n",
      "Question   Prediction   Answer\n",
      "321+65     386          386     \u001b[92m ☑ \u001b[0m\n",
      "36+853     889          889     \u001b[92m ☑ \u001b[0m\n",
      "589+23     612          612     \u001b[92m ☑ \u001b[0m\n",
      "125+660    785          785     \u001b[92m ☑ \u001b[0m\n",
      "4+886      880          890     \u001b[91m ☒ \u001b[0m\n",
      "357+671    1028         1028    \u001b[92m ☑ \u001b[0m\n",
      "15+132     147          147     \u001b[92m ☑ \u001b[0m\n",
      "107+30     137          137     \u001b[92m ☑ \u001b[0m\n",
      "7+572      579          579     \u001b[92m ☑ \u001b[0m\n",
      "260+2      262          262     \u001b[92m ☑ \u001b[0m\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 6\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 11s 241us/step - loss: 0.0440 - acc: 0.9933 - val_loss: 0.0349 - val_acc: 0.9958\n",
      "Question   Prediction   Answer\n",
      "65+922     987          987     \u001b[92m ☑ \u001b[0m\n",
      "554+27     581          581     \u001b[92m ☑ \u001b[0m\n",
      "69+11      80           80      \u001b[92m ☑ \u001b[0m\n",
      "719+483    1202         1202    \u001b[92m ☑ \u001b[0m\n",
      "336+37     373          373     \u001b[92m ☑ \u001b[0m\n",
      "900+408    1308         1308    \u001b[92m ☑ \u001b[0m\n",
      "5+570      575          575     \u001b[92m ☑ \u001b[0m\n",
      "871+836    1707         1707    \u001b[92m ☑ \u001b[0m\n",
      "43+106     149          149     \u001b[92m ☑ \u001b[0m\n",
      "666+941    1607         1607    \u001b[92m ☑ \u001b[0m\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 7\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 11s 241us/step - loss: 0.0609 - acc: 0.9851 - val_loss: 0.0505 - val_acc: 0.9886\n",
      "Question   Prediction   Answer\n",
      "38+952     990          990     \u001b[92m ☑ \u001b[0m\n",
      "64+136     200          200     \u001b[92m ☑ \u001b[0m\n",
      "850+829    1679         1679    \u001b[92m ☑ \u001b[0m\n",
      "9+261      270          270     \u001b[92m ☑ \u001b[0m\n",
      "811+38     849          849     \u001b[92m ☑ \u001b[0m\n",
      "124+534    658          658     \u001b[92m ☑ \u001b[0m\n",
      "294+473    757          767     \u001b[91m ☒ \u001b[0m\n",
      "438+384    822          822     \u001b[92m ☑ \u001b[0m\n",
      "67+194     261          261     \u001b[92m ☑ \u001b[0m\n",
      "1+685      686          686     \u001b[92m ☑ \u001b[0m\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 8\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 11s 240us/step - loss: 0.0266 - acc: 0.9976 - val_loss: 0.0269 - val_acc: 0.9972\n",
      "Question   Prediction   Answer\n",
      "606+84     690          690     \u001b[92m ☑ \u001b[0m\n",
      "46+497     543          543     \u001b[92m ☑ \u001b[0m\n",
      "804+435    1239         1239    \u001b[92m ☑ \u001b[0m\n",
      "64+776     840          840     \u001b[92m ☑ \u001b[0m\n",
      "784+487    1271         1271    \u001b[92m ☑ \u001b[0m\n",
      "42+562     604          604     \u001b[92m ☑ \u001b[0m\n",
      "367+547    914          914     \u001b[92m ☑ \u001b[0m\n",
      "64+7       71           71      \u001b[92m ☑ \u001b[0m\n",
      "755+503    1258         1258    \u001b[92m ☑ \u001b[0m\n",
      "617+9      626          626     \u001b[92m ☑ \u001b[0m\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 9\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 11s 242us/step - loss: 0.0195 - acc: 0.9988 - val_loss: 0.0229 - val_acc: 0.9971\n",
      "Question   Prediction   Answer\n",
      "822+868    1690         1690    \u001b[92m ☑ \u001b[0m\n",
      "29+997     1026         1026    \u001b[92m ☑ \u001b[0m\n",
      "75+75      150          150     \u001b[92m ☑ \u001b[0m\n",
      "339+189    528          528     \u001b[92m ☑ \u001b[0m\n",
      "596+790    1386         1386    \u001b[92m ☑ \u001b[0m\n",
      "229+283    512          512     \u001b[92m ☑ \u001b[0m\n",
      "888+916    1704         1804    \u001b[91m ☒ \u001b[0m\n",
      "368+545    913          913     \u001b[92m ☑ \u001b[0m\n",
      "958+18     976          976     \u001b[92m ☑ \u001b[0m\n",
      "97+632     729          729     \u001b[92m ☑ \u001b[0m\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 10\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 11s 247us/step - loss: 0.0403 - acc: 0.9906 - val_loss: 0.1849 - val_acc: 0.9342\n",
      "Question   Prediction   Answer\n",
      "940+766    1706         1706    \u001b[92m ☑ \u001b[0m\n",
      "715+8      723          723     \u001b[92m ☑ \u001b[0m\n",
      "96+358     455          454     \u001b[91m ☒ \u001b[0m\n",
      "23+24      48           47      \u001b[91m ☒ \u001b[0m\n",
      "535+87     623          622     \u001b[91m ☒ \u001b[0m\n",
      "23+25      48           48      \u001b[92m ☑ \u001b[0m\n",
      "9+305      314          314     \u001b[92m ☑ \u001b[0m\n",
      "91+470     561          561     \u001b[92m ☑ \u001b[0m\n",
      "391+523    814          914     \u001b[91m ☒ \u001b[0m\n",
      "4+598      602          602     \u001b[92m ☑ \u001b[0m\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 11\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 11s 252us/step - loss: 0.0324 - acc: 0.9930 - val_loss: 0.0186 - val_acc: 0.9976\n",
      "Question   Prediction   Answer\n",
      "495+569    1064         1064    \u001b[92m ☑ \u001b[0m\n",
      "123+915    1038         1038    \u001b[92m ☑ \u001b[0m\n",
      "20+809     829          829     \u001b[92m ☑ \u001b[0m\n",
      "304+443    747          747     \u001b[92m ☑ \u001b[0m\n",
      "941+33     974          974     \u001b[92m ☑ \u001b[0m\n",
      "0+98       99           98      \u001b[91m ☒ \u001b[0m\n",
      "999+53     1052         1052    \u001b[92m ☑ \u001b[0m\n",
      "5+297      302          302     \u001b[92m ☑ \u001b[0m\n",
      "7+469      476          476     \u001b[92m ☑ \u001b[0m\n",
      "55+885     940          940     \u001b[92m ☑ \u001b[0m\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 12\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 11s 253us/step - loss: 0.0124 - acc: 0.9994 - val_loss: 0.0143 - val_acc: 0.9987\n",
      "Question   Prediction   Answer\n",
      "1+411      412          412     \u001b[92m ☑ \u001b[0m\n",
      "597+22     619          619     \u001b[92m ☑ \u001b[0m\n",
      "629+31     660          660     \u001b[92m ☑ \u001b[0m\n",
      "975+89     1064         1064    \u001b[92m ☑ \u001b[0m\n",
      "82+617     699          699     \u001b[92m ☑ \u001b[0m\n",
      "506+29     535          535     \u001b[92m ☑ \u001b[0m\n",
      "945+1      946          946     \u001b[92m ☑ \u001b[0m\n",
      "29+853     882          882     \u001b[92m ☑ \u001b[0m\n",
      "55+323     378          378     \u001b[92m ☑ \u001b[0m\n",
      "55+119     174          174     \u001b[92m ☑ \u001b[0m\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 13\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 11s 246us/step - loss: 0.0107 - acc: 0.9995 - val_loss: 0.0138 - val_acc: 0.9983\n",
      "Question   Prediction   Answer\n",
      "527+924    1451         1451    \u001b[92m ☑ \u001b[0m\n",
      "64+628     692          692     \u001b[92m ☑ \u001b[0m\n",
      "659+0      659          659     \u001b[92m ☑ \u001b[0m\n",
      "579+36     615          615     \u001b[92m ☑ \u001b[0m\n",
      "50+474     524          524     \u001b[92m ☑ \u001b[0m\n",
      "607+86     693          693     \u001b[92m ☑ \u001b[0m\n",
      "61+905     966          966     \u001b[92m ☑ \u001b[0m\n",
      "53+408     461          461     \u001b[92m ☑ \u001b[0m\n",
      "997+46     1043         1043    \u001b[92m ☑ \u001b[0m\n",
      "300+1      301          301     \u001b[92m ☑ \u001b[0m\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 14\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 11s 246us/step - loss: 0.0441 - acc: 0.9876 - val_loss: 0.0258 - val_acc: 0.9940\n",
      "Question   Prediction   Answer\n",
      "92+821     913          913     \u001b[92m ☑ \u001b[0m\n",
      "58+511     569          569     \u001b[92m ☑ \u001b[0m\n",
      "227+762    989          989     \u001b[92m ☑ \u001b[0m\n",
      "929+0      929          929     \u001b[92m ☑ \u001b[0m\n",
      "63+37      100          100     \u001b[92m ☑ \u001b[0m\n",
      "935+390    1325         1325    \u001b[92m ☑ \u001b[0m\n",
      "17+126     143          143     \u001b[92m ☑ \u001b[0m\n",
      "5+852      857          857     \u001b[92m ☑ \u001b[0m\n",
      "818+10     828          828     \u001b[92m ☑ \u001b[0m\n",
      "749+958    1607         1707    \u001b[91m ☒ \u001b[0m\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 15\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 11s 250us/step - loss: 0.0113 - acc: 0.9991 - val_loss: 0.0109 - val_acc: 0.9990\n",
      "Question   Prediction   Answer\n",
      "866+759    1625         1625    \u001b[92m ☑ \u001b[0m\n",
      "213+357    570          570     \u001b[92m ☑ \u001b[0m\n",
      "684+8      692          692     \u001b[92m ☑ \u001b[0m\n",
      "77+828     905          905     \u001b[92m ☑ \u001b[0m\n",
      "20+692     712          712     \u001b[92m ☑ \u001b[0m\n",
      "30+877     907          907     \u001b[92m ☑ \u001b[0m\n",
      "37+1       38           38      \u001b[92m ☑ \u001b[0m\n",
      "334+77     411          411     \u001b[92m ☑ \u001b[0m\n",
      "821+666    1487         1487    \u001b[92m ☑ \u001b[0m\n",
      "29+889     918          918     \u001b[92m ☑ \u001b[0m\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 16\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "35200/45000 [======================>.......] - ETA: 2s - loss: 0.0073 - acc: 0.9997"
     ]
    }
   ],
   "source": [
    "# Train the model each epoch and show predictions against the validation dataset.\n",
    "for iteration in range(1, 5):\n",
    "    print()\n",
    "    print('-' * 50)\n",
    "    print('Iteration', iteration)\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=BATCH_SIZE,\n",
    "              epochs=1,\n",
    "              validation_data=(x_val, y_val))\n",
    "    # Select 10 samples from the validation set at random so we can visualize errors.\n",
    "    print(\"Question   Prediction   Answer\")\n",
    "    for i in range(10):\n",
    "        ind = np.random.randint(0, len(x_val))\n",
    "        rowx, rowy = x_val[np.array([ind])], y_val[np.array([ind])]\n",
    "        preds = model.predict_classes(rowx, verbose=0)\n",
    "        q = ctable.decode(rowx[0])\n",
    "        correct = ctable.decode(rowy[0])\n",
    "        prediction = ctable.decode(preds[0], calc_argmax=False)\n",
    "        \n",
    "        print(q[::-1] if REVERSE else q, \"  \", prediction, \"       \", correct, \"  \", colors.ok if prediction == correct else colors.fail, \"☑\" if prediction == correct else \"☒\", colors.close)\n",
    "\n",
    "score = model.evaluate(x_val, y_val, verbose=0)\n",
    "print('\\nTest loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
